{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False):\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      0.99        88\n",
      "          1       0.99      0.97      0.98        91\n",
      "          2       0.99      0.99      0.99        86\n",
      "          3       0.98      0.87      0.92        91\n",
      "          4       0.99      0.96      0.97        92\n",
      "          5       0.95      0.97      0.96        91\n",
      "          6       0.99      0.99      0.99        91\n",
      "          7       0.96      0.99      0.97        89\n",
      "          8       0.94      1.00      0.97        88\n",
      "          9       0.93      0.98      0.95        92\n",
      "\n",
      "avg / total       0.97      0.97      0.97       899\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[87  0  0  0  1  0  0  0  0  0]\n",
      " [ 0 88  1  0  0  0  0  0  1  1]\n",
      " [ 0  0 85  1  0  0  0  0  0  0]\n",
      " [ 0  0  0 79  0  3  0  4  5  0]\n",
      " [ 0  0  0  0 88  0  0  0  0  4]\n",
      " [ 0  0  0  0  0 88  1  0  0  2]\n",
      " [ 0  1  0  0  0  0 90  0  0  0]\n",
      " [ 0  0  0  0  0  1  0 88  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 88  0]\n",
      " [ 0  0  0  1  0  1  0  0  0 90]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAADuCAYAAAAZZe3jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA0grYEeUY+zmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2688927400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Standard scientific Python imports\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import datasets, classifiers and performance metrics\n",
    "from sklearn import datasets, svm, metrics\n",
    "\n",
    "# The digits dataset\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# The data that we are interested in is made of 8x8 images of digits, let's\n",
    "# have a look at the first 4 images, stored in the `images` attribute of the\n",
    "# dataset.  If we were working from image files, we could load them using\n",
    "# matplotlib.pyplot.imread.  Note that each image must have the same size. For these\n",
    "# images, we know which digit they represent: it is given in the 'target' of\n",
    "# the dataset.\n",
    "images_and_labels = list(zip(digits.images, digits.target))\n",
    "for index, (image, label) in enumerate(images_and_labels[:4]):\n",
    "    plt.subplot(2, 4, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Training: %i' % label)\n",
    "\n",
    "# To apply a classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))\n",
    "\n",
    "# Create a classifier: a support vector classifier\n",
    "classifier = svm.SVC(gamma=0.001)\n",
    "\n",
    "# We learn the digits on the first half of the digits\n",
    "classifier.fit(data[:n_samples // 2], digits.target[:n_samples // 2])\n",
    "\n",
    "# Now predict the value of the digit on the second half:\n",
    "expected = digits.target[n_samples // 2:]\n",
    "predicted = classifier.predict(data[n_samples // 2:])\n",
    "\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (classifier, metrics.classification_report(expected, predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))\n",
    "\n",
    "images_and_predictions = list(zip(digits.images[n_samples // 2:], predicted))\n",
    "for index, (image, prediction) in enumerate(images_and_predictions[:4]):\n",
    "    plt.subplot(2, 4, index + 5)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Prediction: %i' % prediction)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image \n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare(df):\n",
    "    return df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(v):\n",
    "    image_file = v['image'].convert('L')\n",
    "    image_file = image_file.resize((8, 8), Image.BOX)\n",
    "    array = np.asarray(image_file, dtype=np.uint8)\n",
    "    array = list(array.reshape(64))\n",
    "    array = np.array([(255-x) * 1.0 / 10 for x in array], dtype=np.float)\n",
    "    return {'digit': int(classifier.predict([array])[0])}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'digit': 9}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_file = Image.open('nine.png')\n",
    "\n",
    "data_frame = pd.DataFrame([{'image': image_file}])\n",
    "\n",
    "digit = predict(prepare(data_frame))\n",
    "digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import drun.io\n",
    "model = drun.io.export('/drun/image_recognize.model', \n",
    "                       lambda x : predict(x),\n",
    "                       prepare_func=lambda x : prepare(x),\n",
    "                       input_data_frame=data_frame,\n",
    "                       version='1.0')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
