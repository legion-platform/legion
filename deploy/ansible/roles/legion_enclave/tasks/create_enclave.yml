---

# Create kubernetes namespace for enclave
- name: "Remove {{ enclave }} namespace"
  shell: "kubectl --context {{ cluster_name }} delete namespace {{ enclave }} --ignore-not-found=true --grace-period=10"

- name: "Check that {{ enclave }} namespace has been removed"
  shell: "kubectl --context {{ cluster_name }} get namespace {{ enclave }}"
  register: namespace_check
  until: namespace_check.stderr.find(' not found') != -1
  retries: 10
  delay: 10
  ignore_errors: true

- name: WORKAROUND delete pods in phase terminating
  shell: kubectl --context {{ cluster_name }} --namespace {{ enclave }}  delete --grace-period=0 --force po $(kubectl --namespace {{ enclave }} get po -o wide | grep Terminating | awk '{ print $1 }') || true

- name: "Confirm that {{ enclave }} namespace has been removed"
  shell: "kubectl --context {{ cluster_name }} get namespace {{ enclave }}"
  register: namespace_check
  until: namespace_check.stderr.find(' not found') != -1
  retries: 10
  delay: 10
  ignore_errors: true

- name: "Create {{ enclave }} namespace"
  shell: "kubectl --context {{ cluster_name }} create namespace {{ enclave }}"

- name: "Label {{ enclave }} namespace"
  shell: "kubectl --context {{ cluster_name }} label ns {{ enclave }} enclave={{ enclave }} --overwrite"

- name: Copy TLS secret
  shell: "kubectl --context {{ cluster_name }} get secret {{ source_secret_name }} -o json --namespace default | jq '.metadata.namespace = \"{{ enclave }}\"' | jq '.metadata.name = \"{{ root_domain }}-tls\"' | kubectl create --context {{ cluster_name }} -f -"

# Create Airflow RDS resources
- name: Install ansible dependencies
  apt: name="{{ item }}"
  with_items:
    - python-psycopg2
    - postgresql-client
  become: yes

- name: Get Airflow Postgres RDS endpoint
  rds:
    command: facts
    region: "{{ aws_region }}"
    instance_name: "{{ env_name }}-airflow-rds"
  register: airflow_rds_instance_facts

- name: "Create Postgres schema for {{ enclave }} enclave"
  postgresql_schema: 
    database: "{{ aws.rds.database_name }}"
    login_host: "{{ airflow_rds_instance_facts.instance.endpoint }}"
    login_password: "{{ aws.rds.password }}"
    login_user: "{{ aws.rds.username }}"
    state: present
    name: "{{ airflow_db_schema }}"

- name: "Generate {{ enclave }} enclave Postgres user password"
  shell: "tr -d -c 'a-zA-Z0-9' < /dev/urandom | head -c 20"
  register: airflow_db_enclave_pass

- name: "Create Postgres user for {{ enclave }} enclave"
  postgresql_user: 
    db: "{{ aws.rds.database_name }}"
    login_host: "{{ airflow_rds_instance_facts.instance.endpoint }}"
    login_password: "{{ aws.rds.password }}"
    login_user: "{{ aws.rds.username }}"
    state: present
    name: "{{ airflow_db_enclave_user }}"
    password: "{{ airflow_db_enclave_pass.stdout }}"

- name: "Set Postgres user privileges "
  postgresql_privs: 
    db: "{{ aws.rds.database_name }}"
    login_host: "{{ airflow_rds_instance_facts.instance.endpoint }}"
    login_password: "{{ aws.rds.password }}"
    login_user: "{{ aws.rds.username }}"
    role: "{{ airflow_db_enclave_user }}"
    privs: ALL
    type: schema
    objs: "{{ airflow_db_schema }}"
    state: present

- name: Create alter role query
  template:
    src: alter_role.sql.j2
    dest: "{{ tmp_dir }}/alter_role.{{ cluster_name }}.sql"
    mode: 0644

- name: "Set search_path (Schema) for Postgres user"
  shell: PGPASSWORD="{{ aws.rds.password }}" psql -h "{{ airflow_rds_instance_facts.instance.endpoint }}" -U"{{ aws.rds.username }}" < {{ tmp_dir }}/alter_role.{{ cluster_name }}.sql

# Create NFS storage for Airflow
- name: Create PVC configuration
  template:
    src: airflow-pvc.yaml.j2
    dest: "{{ tmp_dir }}/airflow-pvc.{{ cluster_name }}.yaml"
    mode: 0644

- name: Remove old PVC
  shell: 'kubectl --context {{ cluster_name }} delete --ignore-not-found=true --namespace {{ enclave }} -f {{ tmp_dir }}/airflow-pvc.{{ cluster_name }}.yaml'
  ignore_errors: yes

- name: Apply new PVC
  shell: 'kubectl --context {{ cluster_name }} apply --namespace {{ enclave }} -f {{ tmp_dir }}/airflow-pvc.{{ cluster_name }}.yaml'

# Create S3 resources
- name: Create S3 storage for Airflow
  aws_s3:
    bucket: "{{ airflow_s3_bucket_name }}"
    object: "/{{ enclave }}"
    mode: create

# Create IAM roles
- name: Generate Trust policy documents
  template:
    src: "{{ item }}.yaml.j2"
    dest: "{{ tmp_dir }}/{{ item }}.{{ cluster_name }}.yaml"
  with_items:
    - trust_policy

- name: Generate S3 access policy documents
  template:
    src: "{{ item }}.yaml.j2"
    dest: "{{ tmp_dir }}/{{ item }}.{{ enclave }}.{{ cluster_name }}.yaml"
  with_items:
    - airflow_s3_access_policy

- name: Create Airflow IAM role
  iam:
    iam_type: role
    name: "{{ cluster_name }}-{{ enclave }}-airflow-role"
    trust_policy_filepath: "{{ tmp_dir }}/trust_policy.{{ cluster_name }}.yaml"
    state: present

- name: Attach Airflow S3 accesse policy to the role
  iam_policy:
    iam_type: role
    iam_name: "{{ cluster_name }}-{{ enclave }}-airflow-role"
    policy_name: "{{ cluster_name }}-{{ enclave }}-airflow-s3-access-policy"
    policy_document: "{{ tmp_dir }}/airflow_s3_access_policy.{{ enclave }}.{{ cluster_name }}.yaml"
    state: present
